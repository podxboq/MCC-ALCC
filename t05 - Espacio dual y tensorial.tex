\portada

\begin{esquemaExplorador}
  \temaEsquema{Espacio dual}{
    \conceptoEsquema{Definición}{}
    \conceptoEsquema{Propiedades fundamentales}{}
    \conceptoEsquema{Teorema de Riesz-Fréchet}{$f=\langle \cdot, y_f \rangle$}
  }
  \temaEsquema{Producto tensorial}{
    \conceptoEsquema{Definición}{}
    \conceptoEsquema{Base tensorial}{}
  }
  \temaEsquema{Producto externo}{
    \conceptoEsquema{Definición}{$u\wedge v = u\otimes v^\dagger$}
  }
\end{esquemaExplorador}

\unirsection{Ideas clave}

\subsection{Introducción y objetivos}

En este tema profundizaremos en la estructura de los espacios de Hilbert, introduciendo herramientas matemáticas esenciales para la computación cuántica. Si bien en el tema anterior establecimos las bases geométricas de estos espacios, ahora nos centraremos en cómo interactúan diferentes espacios entre sí y en la dualidad inherente a ellos.

Comenzaremos estudiando el \textbf{espacio dual}, un concepto que nos permitirá entender los funcionales lineales y que será la base matemática para la notación de \textbf{bra-ket} de Dirac, el lenguaje estándar de la mecánica cuántica.

Posteriormente, abordaremos la construcción de espacios compuestos mediante el \textbf{producto tensorial}. Esta herramienta es crucial en computación cuántica, ya que es el mecanismo matemático que nos permite describir sistemas de múltiples cúbits y entender el fenómeno del entrelazamiento cuántico.

Finalmente, definiremos el \textbf{producto externo}, una operación que nos permitirá construir operadores a partir de vectores y que resulta fundamental para entender los proyectores y las medidas cuánticas.

Los objetivos del tema son:
\begin{enumerate}
  \item Comprender el concepto de espacio dual y su relación con el espacio original a través del teorema de Riesz-Fréchet.
  \item Dominar la construcción y propiedades del producto tensorial de espacios vectoriales y operadores.
  \item Calcular productos tensoriales de vectores y matrices con soltura.
  \item Entender el producto externo y su aplicación en la construcción de proyectores y la relación de completitud.
\end{enumerate}

\subsection{Espacio dual}

El concepto de espacio dual es fundamental en el análisis funcional y proporciona una perspectiva profunda sobre la estructura de los espacios vectoriales. En computación cuántica, el espacio dual adquiere un significado especial a través de la notación de Dirac, que veremos en el próximo capítulo.

La importancia del espacio dual en matemáticas se manifiesta en varios aspectos:

\begin{itemize}
  \item Proporciona un marco \textbf{unificado} para entender funcionales lineales y formas multilineales.
  \item Permite la \textbf{caracterización completa} de propiedades geométricas mediante funcionales.
  \item Es esencial para la teoría de \textbf{operadores adjuntos} y autoadjuntos.
\end{itemize}

\begin{defi}[Espacio dual]
  Sea $V$ un espacio vectorial. El \textbf{espacio dual} de $V$, denotado $V^*$, es el espacio vectorial de todos los funcionales lineales sobre $V$
  $$V^* = \{f: V \to \C \mid f \text{ es lineal}\}\,.$$
\end{defi}

Las operaciones en $V^*$ se definen puntualmente
\begin{align}
  (f + g)(v)    & = f(v) + g(v) & \forall v \in V                        \\
  (\alpha f)(v) & = \alpha f(v) & \forall v \in V, \forall \alpha \in \C
\end{align}

\begin{theo}[Dimensión del espacio dual]
  \label{th:dimension_dual}
  Sea $V$ un espacio vectorial. Entonces $\dim V^* = \dim V$.
\end{theo}
\begin{proof}
  La demostración se basa en construir una base para el espacio dual a partir de una base del espacio $V$.

  Sea $\{e_1, e_2, \ldots, e_n\}$ una base de $V$. Definimos los funcionales $\{e_1^*, e_2^*, \ldots, e_n^*\}$ mediante
  \begin{equation*}
    e_i^*(e_j) = \delta_{ij} = \begin{cases}
      1 & \text{si } i = j    \\
      0 & \text{si } i \neq j
    \end{cases} \quad \forall i,j \in \{1,2,\ldots,n\}\,.
  \end{equation*}

  Para cualquier $f \in V^*$ y cualquier $v = \sum_{i=1}^n v_i e_i \in V$
  \begin{equation*}
    f(v) = f\left(\sum_{i=1}^n v_i e_i\right) = \sum_{i=1}^n v_i f(e_i) = \sum_{i=1}^n f(e_i) e_i^*(v)\,.
  \end{equation*}

  Por tanto
  \[
    f = \sum_{i=1}^n f(e_i) e_i^*\,,
  \]
  lo que muestra que $\{e_1^*, e_2^*, \ldots, e_n^*\}$ genera $V^*$.

  Para la independencia lineal, supongamos que $\sum_{i=1}^n \alpha_i e_i^* = 0$ para ciertos $\alpha_i \in \C$. Entonces evaluando en cada elemento de la base de $V$ obtenemos
  \begin{equation*}
    0 = \sum_{i=1}^n \alpha_i e_i^* = \sum_{i=1}^n \alpha_i e_i^*(e_j) = \sum_{i=1}^n \alpha_i \delta_{ij} = \alpha_j \quad \forall j \in \{1,2,\ldots,n\}\,.
  \end{equation*}

  Por lo tanto $\alpha_j = 0$ para todo $j \in \{1,2,\ldots,n\}$, lo que muestra que $\{e_1^*, e_2^*, \ldots, e_n^*\}$ es una base de $V^*$.
\end{proof}

Este resultado justifica la siguiente definición.

\begin{defi}[Base dual]
  Si $\{e_1, e_2, \ldots, e_n\}$ es una base de $V$, la \textbf{base dual} $\{e_1^*, e_2^*, \ldots, e_n^*\}$ de $V^*$ se define por
  $$e_i^*(e_j) = \delta_{ij}\,.$$
\end{defi}

Los resultados expuestos a continuación requieren de conocimientos avanzados en análisis funcional y teoría de espacios de Hilbert. No haremos las demostraciones de estos resultados, y se incluyen para entender la importancia del espacio dual y su conexión con la notación de Dirac.

Se recomienda consultar las referencias bibliográficas al final del tema para una comprensión más profunda.

En espacios de Hilbert, existe una correspondencia especial entre el espacio dual y el producto interno.

\begin{theo}[Teorema de Riesz-Fréchet]
  Sea $\mathcal{H}$ un espacio de Hilbert complejo con producto interno $\langle \cdot, \cdot \rangle$. Para cada funcional lineal continuo $f \in \mathcal{H}^*$, existe un único elemento $y_f \in \mathcal{H}$ tal que:
  $$f(x) = \langle y_f, x \rangle \quad \forall x \in \mathcal{H}\,.$$
  La aplicación $\Phi: \mathcal{H} \to \mathcal{H}^*$ definida por $\Phi(x)(y) = \langle y, x \rangle$ es un isomorfismo antilineal isométrico.
\end{theo}

Si $V$ es un espacio vectorial, y $\mathcal{B}=\{e_1, e_2, \ldots, e_n\}$ es una base ortonormal de $V$, entonces
\[
  \mathcal{B}^*=\{\langle e_1, - \rangle, \langle e_2, - \rangle, \ldots, \langle e_n, - \rangle\}\,,
\]
es una base de $V^*$.

\subsection{Producto tensorial}

Sean $V$ y $W$ dos espacios vectoriales. El producto tensorial es, el espacio vectorial más pequeño que contiene todos los productos formales de la forma $v \otimes w$, para $v \in V$ y $w \in W$, y que respeta la bilinealidad.

\begin{defi}
  El \textbf{producto tensorial} de dos espacios vectoriales $V$ y $W$, denotado por $V \otimes W$, es el espacio vectorial generado por los productos tensoriales simples $v \otimes w$, donde $v \in V$ y $w \in W$, sujeto a las relaciones de bilinealidad.
\end{defi}

Para no dejar dudas y respetar la formalidad del concepto, daremos la definición formal del producto tensorial.

El producto tensorial $V \otimes W$ se construye a partir del espacio vectorial libre $F(V \times W)$ generado por los pares ordenados $(v, w) \in V \times W$, factorizando por el subespacio $R$ generado por las relaciones de \textbf{bilinealidad}:
\begin{enumerate}
  \item \textbf{Linealidad en el primer argumento:}
        $$(\alpha v_1 + \beta v_2, w) - \alpha (v_1, w) - \beta (v_2, w)$$
  \item \textbf{Linealidad en el segundo argumento:}
        $$(v, \alpha w_1 + \beta w_2) - \alpha (v, w_1) - \beta (v, w_2)$$
\end{enumerate}
donde $v, v_1, v_2 \in V$, $w, w_1, w_2 \in W$, y $\alpha, \beta \in \C$.

El \textbf{producto tensorial} es el espacio cociente
$$V \otimes W := F(V \times W) / R\,.$$

El \textbf{tensor simple} $v \otimes w$ es la clase de equivalencia del par $(v, w)$ en el espacio cociente.

Al trabajar con espacios vectoriales de dimensión finita, podemos entender cómo se construyen las bases en el producto tensorial y por tanto su estructura.

\begin{prop}
  Sea $V$ un espacio vectorial de dimensión $n$ y $W$ un espacio vectorial de dimensión $m$. Si $\mathcal{B}_{V}=\{v_i\}_{i=1}^n$ es una base para $V$ y $\mathcal{B}_{W}=\{w_j\}_{j=1}^m$ es una base para $W$, entonces el conjunto de tensores simples
  $$
    \mathcal{B}_{V \otimes W} = \{v_i \otimes w_j\}_{i=1,\ldots,n}^{j=1,\ldots,m}\,,
  $$
  es una base para $V \otimes W$.
\end{prop}

Como consecuencia del resultado anterior, todo elemento $t \in V \otimes W$ puede escribirse de manera única como una combinación lineal de los elementos de la base
$$t = \sum_{i=1}^n \sum_{j=1}^m \alpha_{ij} (v_i \otimes w_j)\,,$$
donde $\alpha_{ij} \in \mathbb{C}$.

Además, la dimensión del espacio tensorial es el producto de las dimensiones de los espacios originales
$$\text{dim}(V \otimes W) = \text{dim}(V) \cdot \text{dim}(W) = n \cdot m\,.$$


\begin{defi}
  Sea $V$ y $W$ dos espacios vectoriales.
  Un elemento $t \in V \otimes W$ que puede escribirse como $t = v \otimes w$, con $v\in V$ y $w\in W$, se llama \textbf{tensor simple} o \textbf{producto separable}.
\end{defi}

\begin{prop}
  Sea $V$ y $W$ dos espacios vectoriales, $v \in V$, $w \in W$ y $\alpha \in \C$. Entonces sobre la definición del producto tensorial se cumplen las siguientes propiedades:
  \begin{itemize}
    \item \textbf{linealidad en el primer argumento:}
          $$(u + v) \otimes w = u \otimes w + v \otimes w\,.$$
    \item \textbf{linealidad en el segundo argumento:}
          $$u \otimes (v + w) = u \otimes v + u \otimes w\,.$$
    \item \textbf{linealidad por escalares:}
          $$\alpha (u \otimes v) = (\alpha u) \otimes v = u \otimes (\alpha v)\,.$$
  \end{itemize}
\end{prop}

\begin{eje}
  Sean $V$ y $W$ dos espacios vectoriales, podemos definir un producto interno sobre los vectores separables de $V \otimes W$ como
  \begin{equation*}
    \langle v \otimes w, v^\prime \otimes w^\prime \rangle = \langle v, v^\prime \rangle \langle w, w^\prime \rangle\,.
  \end{equation*}
  para $v, v^\prime \in V$ y $w, w^\prime \in W$.

  Entonces podemos definir para cualquier par de vectores de $V\otimes W$ el producto interno como
  \begin{equation*}
    \langle \sum_{i,j=1}^n \alpha_{ij} v_i \otimes w_j, \sum_{k,l=1}^m \beta_{kl} v^\prime_k \otimes w^\prime_l \rangle = \sum_{i,j=1}^n \sum_{k,l=1}^m \alpha_{ij} \beta_{kl} \langle v_i, v^\prime_k \rangle \langle w_j, w^\prime_l \rangle\,.
  \end{equation*}
\end{eje}

\begin{eje}
  Sea $V=\C^2$ y los vectores canónicos $e_1$ y $e_2$. Entonces
  \[
    e_1\otimes e_1 + e_2\otimes e_2
  \]
  no es separable.
  Supongamos que es separable, es decir, que existen $v,w\in V$ tales que
  \[
    e_1\otimes e_1 + e_2\otimes e_2 = v\otimes w\,.
  \]
  Como $v\in V$ y $w\in W$, podemos escribir $v=\alpha e_1 + \beta e_2$ y $w=\gamma e_1 + \delta e_2$ para ciertos $\alpha, \beta, \gamma, \delta \in \C$. Entonces
  \begin{align*}
    e_1\otimes e_1 + e_2\otimes e_2 & = (\alpha e_1 + \beta e_2)\otimes (\gamma e_1 + \delta e_2)                                                                  \\
                                    & = \alpha \gamma e_1\otimes e_1 + \alpha \delta e_1\otimes e_2 + \beta \gamma e_2\otimes e_1 + \beta \delta e_2\otimes e_2\,.
  \end{align*}

  Por la unicidad de descomposición en una base, debemos tener las siguientes ecuaciones
  \begin{align*}
    \alpha \gamma & = 1 \\
    \alpha \delta & = 0 \\
    \beta \gamma  & = 0 \\
    \beta \delta  & = 1
  \end{align*}
  que no tienen solución.
\end{eje}

\subsection{Producto tensorial de operadores y matrices}
Podemos extender la definición del producto tensorial a operadores lineales entre espacios vectoriales de manera natural.
\begin{defi}
  Si $A: V_1 \to V_2$ y $B: W_1 \to W_2$ son operadores lineales, podemos definir el \textbf{operador tensorial} $A \otimes B$ en el espacio tensorial $V_1 \otimes W_1$, como
  \begin{align*}
    A \otimes B : V_1 \times W_1                            & \to V_2 \times W_2                                                       \\
    \sum_{i=1}^n \sum_{j=1}^m \alpha_{ij} (v_i \otimes w_j) & \mapsto \sum_{i=1}^n \sum_{j=1}^m \alpha_{ij} (A(v_i) \otimes B(w_j))\,.
  \end{align*}

\end{defi}

De igual manera, podemos definir el producto tensorial de matrices, siendo esta forma la más habitual de trabajar con el producto vectorial.

\begin{defi}
  Sean $A \in M_{n \times m}(\C)$ y $B \in M_{p \times q}(\C)$ dos matrices complejas. El \textbf{producto tensorial matricial} $A \otimes B$ es una matriz en $M_{np \times mq}(\C)$ definida por
  $$
    (A \otimes B)_{(i,j),(k,l)} = A_{ik} B_{jl}
  $$
  para $1 \leq i \leq n$, $1 \leq j \leq m$, $1 \leq k \leq p$, $1 \leq l \leq q$.
\end{defi}

Es decir, si
$$A = \begin{pmatrix}
    a_{11} & a_{12} & \ldots & a_{1m} \\
    a_{21} & a_{22} & \ldots & a_{2m} \\
    \vdots & \vdots & \ddots & \vdots \\
    a_{n1} & a_{n2} & \ldots & a_{nm}
  \end{pmatrix} \text{ y } \quad B = \begin{pmatrix}
    b_{11} & b_{12} & \ldots & b_{1q} \\
    b_{21} & b_{22} & \ldots & b_{2q} \\
    \vdots & \vdots & \ddots & \vdots \\
    b_{p1} & b_{p2} & \ldots & b_{pq}
  \end{pmatrix},$$
entonces
\begin{align*}
  A \otimes B & = \begin{pmatrix}
                    a_{11}B & a_{12}B & \ldots & a_{1m}B \\
                    a_{21}B & a_{22}B & \ldots & a_{2m}B \\
                    \vdots  & \vdots  & \ddots & \vdots  \\
                    a_{n1}B & a_{n2}B & \ldots & a_{nm}B
                  \end{pmatrix}                                                                                       \\
              & =\begin{pmatrix}
                   a_{11}b_{11} & \ldots & a_{12}b_{1q} & a_{12}b_{11} & \ldots & a_{12}b_{1q} & \ldots & a_{1m}b_{11} & \ldots & a_{1m}b_{1q} \\
                   a_{11}b_{21} & \ldots & a_{11}b_{2q} & a_{12}b_{21} & \ldots & a_{12}b_{2q} & \ldots & a_{1m}b_{21} & \ldots & a_{1m}b_{2q} \\
                   \vdots       & \ddots & \vdots       & \vdots       & \ddots & \vdots       & \ldots & \vdots       & \ddots & \vdots       \\
                   a_{11}b_{p1} & \ldots & a_{11}b_{pq} & a_{12}b_{p1} & \ldots & a_{12}b_{pq} & \ldots & a_{1m}b_{p1} & \ldots & a_{1m}b_{pq}
                 \end{pmatrix}\,.
\end{align*}

Finalmente es importante resaltar que la representación matricial del producto tensorial de operadores lineales es la misma que la del producto tensorial de matrices.

\begin{prop}
  Sea $T\in\mathcal{L}(V)$ y $S\in\mathcal{L}(W)$ dos operadores lineales entre espacios vectoriales $V$ y $W$. Entonces
  \[
    [T\otimes S] = [T]\otimes[S]\,.
  \]
\end{prop}

\begin{eje}
  Consideremos las matrices ya utilizadas en otros ejemplos:
  \[
    X = \begin{pmatrix} 0 & 1 \\ 1 & 0 \end{pmatrix}\,, \quad Y = \begin{pmatrix} 1 & 0 \\ 0 & -1 \end{pmatrix}\,.
  \]
  Entonces
  \begin{align*}
    X \otimes Y & = \begin{pmatrix} 0 & 1 \\ 1 & 0 \end{pmatrix} \otimes \begin{pmatrix} 1 & 0 \\ 0 & -1 \end{pmatrix} = \begin{pmatrix} 0 \begin{pmatrix} 1 & 0 \\ 0 & -1 \end{pmatrix} & 1 \begin{pmatrix} 1 & 0 \\ 0 & -1 \end{pmatrix} \\ 1 \begin{pmatrix} 1 & 0 \\ 0 & -1 \end{pmatrix} & 0 \begin{pmatrix} 1 & 0 \\ 0 & -1 \end{pmatrix} \end{pmatrix}  \\
                & = \begin{pmatrix} 0 & 0 & 1 & 0 \\ 0 & 0 & 0 & -1 \\ 1 & 0 & 0 & 0 \\ 0 & -1 & 0 & 0 \end{pmatrix}\,.                                                                                                                                                            \\
    Y \otimes X & = \begin{pmatrix} 1 & 0 \\ 0 & -1 \end{pmatrix} \otimes \begin{pmatrix} 0 & 1 \\ 1 & 0 \end{pmatrix} = \begin{pmatrix} 1 \begin{pmatrix} 0 & 1 \\ 1 & 0 \end{pmatrix} & 0 \begin{pmatrix} 0 & 1 \\ 1 & 0 \end{pmatrix} \\ 0 \begin{pmatrix} 0 & 1 \\ 1 & 0 \end{pmatrix} & -1 \begin{pmatrix} 0 & 1 \\ 1 & 0 \end{pmatrix} \end{pmatrix} \\
                & = \begin{pmatrix} 0 & 1 & 0 & 0 \\ 1 & 0 & 0 & 0 \\ 0 & 0 & 0 & -1 \\ 0 & 0 & -1 & 0 \end{pmatrix}\,.
  \end{align*}
\end{eje}

Del ejemplo anterior, podemos sacar como conclusión que en general, el producto tensorial no es conmutativo.

\subsection{Producto externo}

Una vez que hemos definido el producto tensorial, podemos definir el producto externo.

\begin{defi}
  Dado un espacio vectorial $V$, se define el \textbf{producto externo} de dos vectores $u, v \in V$ por
  $$u \wedge v = u \otimes v^\dagger\,.$$
\end{defi}

Si con respecto la base canónica, $u = \sum_{i=1}^n u_i e_i$ y $v = \sum_{j=1}^n v_j e_j$, entonces
$$u \wedge v = \sum_{i,j=1}^n u_i \bar{v}_j e_i \otimes e_j^\dagger= \sum_{i,j=1}^n u_i \bar{v}_j e_i \wedge e_j\,.$$

Pero la expresión $e_i\wedge e_j$ es la matriz con todas sus entradas cero excepto en la posición de la fila $i$ y columna $j$ que vale $1$. Por lo tanto, expresado el producto externo como una matriz
\[
  [u \wedge v] = \begin{pmatrix}
    u_1 \bar{v}_1 & u_1 \bar{v}_2 & \dots  & u_1 \bar{v}_n \\
    u_2 \bar{v}_1 & u_2 \bar{v}_2 & \dots  & u_2 \bar{v}_n \\
    \vdots        & \vdots        & \ddots & \vdots        \\
    u_n \bar{v}_1 & u_n \bar{v}_2 & \dots  & u_n \bar{v}_n
  \end{pmatrix}\,.
\]

Si multiplicamos por un vector $w=\mqty(w_1\\ \vdots\\ w_n) \in V$, obtenemos la siguiente igualdad
\begin{align*}
  [u \wedge v]w & = \begin{pmatrix}
                      u_1 \bar{v}_1 & u_1 \bar{v}_2 & \dots  & u_1 \bar{v}_n \\
                      u_2 \bar{v}_1 & u_2 \bar{v}_2 & \dots  & u_2 \bar{v}_n \\
                      \vdots        & \vdots        & \ddots & \vdots        \\
                      u_n \bar{v}_1 & u_n \bar{v}_2 & \dots  & u_n \bar{v}_n
                    \end{pmatrix}\mqty(w_1 \\ \vdots\\ w_n)                                  \\
                & = \mqty(u_1 \bar{v}_1 w_1 + \dots + u_1 \bar{v}_n w_n    \\ \vdots\\ u_n \bar{v}_1 w_1 + \dots + u_n \bar{v}_n w_n) \\
                & = \mqty((w_1 \bar{v}_1 + \dots + w_n \bar{v}_n)u_1       \\ \vdots\\ (w_1 \bar{v}_1 + \dots + w_n \bar{v}_n)u_n)      \\
                & = \mqty(\langle v, w\rangle u_1                          \\ \vdots\\ \langle v, w\rangle u_n) = \langle v, w\rangle u\,.
\end{align*}
Por lo tanto como operadores se cumple
$$ (u \wedge v)(w) = \langle v, w\rangle u\,.$$

En términos del producto externo, podemos reescribir la expresión de un vector con respecto a una base ortonormal como
$$u = \sum_{i=1}^n \langle u, e_i\rangle e_i = \sum_{i=1}^n e_i \wedge e_i(u)=\left( \sum_{i=1}^n e_i \wedge e_i\right)(u)\,.$$

La igualdad anterior nos demuestra el siguiente resultado

\begin{theo}[Relación de completitud]
  Sea $V$ un espacio vectorial y $\mathcal{B}=\{e_1, \ldots, e_n\}$ una base ortonormal de $V$. Entonces
  \[
    \sum_{i=1}^n e_i \wedge e_i = I_V\,.
  \]
\end{theo}

\begin{defi}
  Sea $V$ un espacio vectorial y $\mathcal{B}=\{e_1, \ldots, e_n\}$ una base ortonormal de $V$. Llamamos proyector sobre $e_i$ al operador $P_i = e_i \wedge e_i$.
\end{defi}