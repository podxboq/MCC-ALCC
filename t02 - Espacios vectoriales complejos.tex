\portada

\begin{esquemaExplorador}
  \temaEsquema{Vectores complejos}{
    \conceptoEsquema{Definición y representación}{}
    \conceptoEsquema{Operaciones vectoriales}{}
    \conceptoEsquema{Producto escalar complejo}{}
  }
  \temaEsquema{Estructura algebraica}{
    \conceptoEsquema{Axiomas de espacio vectorial}{}
    \conceptoEsquema{Subespacios vectoriales}{}
    \conceptoEsquema{Propiedades fundamentales}{}
  }
  \temaEsquema{Dependencia e independencia}{
    \conceptoEsquema{Combinaciones lineales}{}
    \conceptoEsquema{Independencia lineal}{}
    \conceptoEsquema{Sistemas generadores}{}
  }
  \temaEsquema{Bases y dimensión}{
    \conceptoEsquema{Concepto de base}{}
    \conceptoEsquema{Base canónica}{}
    \conceptoEsquema{Dimensión finita}{}
  }
\end{esquemaExplorador}

\unirsection{Ideas clave}

\subsection{Introducción y objetivos}

Un \textbf{espacio vectorial} es una estructura algebraica creada a partir de un conjunto no vacío, una operación interna llamada suma (definida para los elementos del conjunto) y una operación externa llamada producto por un escalar (definida entre dicho conjunto y otro conjunto con estructura de cuerpo) que satisface ocho propiedades fundamentales.

Los espacios vectoriales se concibieron como una herramienta de geometría afín gracias a la introducción de coordenadas en el plano bidimensional y el espacio tridimensional.
Desde entonces, se ha visto que hay infinidad de espacios vectoriales además de \(\mathbb{R}^{n}\), como por ejemplo el espacio vectorial de las matrices o de los polinomios.

En este tema dejaremos los números reales de lado y usaremos los números complejos como cuerpo del espacio vectorial, presentaremos las principales definiciones y resultados relacionados con los espacios vectoriales, usando multitud de ejemplos para ofrecer una mejor comprensión de los conceptos abordados.

Más concretamente, los objetivos que trataremos de alcanzar en este tema
serán los siguientes:

\begin{itemize}
  \item Comprobar si cierto conjunto dotado de dos operaciones es un espacio vectorial.
  \item Identificar cuando un subconjuto de un espacio vectoria, hereda la estructura de espacio vectorial.
  \item Razonar si una colección de vectores es linealmente independiente y si conforma o no un sistema generador o una base.
  \item Hallar el mínimo número de vectores que se necesitan para formar base de un subespacio vectorial y usarlo para obtener la dimensión del espacio.
  \item Saber cómo expresar vectores con bases diferentes y el procedimiento para relacionar dichas representaciones.
  \item Calcular la intersección y suma de subespacios.
\end{itemize}

Esta base teórica será fundamental para comprender en los próximos temas la manipulación de estados cuánticos como vectores.

\subsection{Espacio vectorial}

\begin{defi}
  Sea $\K$ un conjunto no vacio junto con una operación interna ($\circ$).
  Diremos que $(\K, \circ)$ es un \textbf{grupo} si verifica:
  \begin{enumerate}
    \item[\likeitem{G1}] La propiedad \textbf{asociativa}
          \[
            \forall a,b,c\in\K\Rightarrow a\circ(b\circ c) = (a\circ b)\circ c\,.
          \]
    \item[\likeitem{G2}] La propiedad \textbf{conmutativa}
          \[
            \forall a,b\in\K\Rightarrow a\circ b = b\circ a\,.
          \]
    \item[\likeitem{G3}] La existencia de \textbf{neutro}
          \[
            \exists! N\in\K \mid\forall a\in\K \Rightarrow a\circ N = a\,.
          \]
    \item[\likeitem{G4}] La existencia de \textbf{opuesto}
          \[
            \forall a\in\K\Rightarrow \exists! O\in\K \mid a\circ O = N\,.
          \]
  \end{enumerate}
\end{defi}

Como ejemplos de grupos tenemos:
\begin{itemize}
  \item $(\Z, +)$, $(\R, +)$, $(\C, +)$.
  \item $(\R^*, \cdot)$, $(\C^*, \cdot)$.
  \item El conjunto de matrices invertibles con la operación de multiplicación.
  \item El conjunto de permutaciones de $n$ elementos con la operación de composición.
  \item Las funciones biyectivas de un conjunto en sí mismo con la operación de composición.
  \item Las rotaciones en el espacio con la composición.
\end{itemize}

\begin{defi}
  Sea $\K$ un conjunto no vacio junto con las operaciones internas de suma (+) y multiplicación ($\cdot$).
  Diremos que $(\K, +, \cdot)$ es un \textbf{cuerpo} si verifica:
  \begin{enumerate}
    \item[\likeitem{C1}] $\K$ con la suma es un grupo.
    \item[\likeitem{C2}] $\K\setminus\{0\}$ con la multiplicación es un grupo.
    \item[\likeitem{C3}] La propiedad \textbf{distributiva} de la multiplicación respecto de la suma.
          \[
            \forall a,b,c\in\K\Rightarrow a\cdot(b+c) = a\cdot b + a\cdot c
          \]
  \end{enumerate}
\end{defi}

Siempre usamos la siguiente notación, con independencia de cuales son los componentes del cuerpo o de la operación que le da su estructura de cuerpo.
\begin{enumerate}
  \item Al neutro de la suma y la multiplicación lo denotamos por $0$ y $1$ respectivamente.
  \item Al elemento opuesto de $a$ para la suma lo denotamos $-a$.
  \item Al elemento opuesto (inverso) de $a$ para la multiplicación lo denotamos $a^{-1}$.
\end{enumerate}

Ejemplos de cuerpos infinitos tenemos $\Q, \R, \C$ y de cuerpos finitos $\Z_p$ para $p\in\N$ primo.
Pero no todos los cuerpos son numéricos, si consideramos el polinomio de grado 1 definido como $p(x)=x-\alpha$ con $\alpha\in\R^*$, entonces bajo la relación de equivalencia de la aritmética residual, el conjunto conciente $\R[X]/ p(x)$ es un cuerpo.

Algunas veces se tiende a igualar el concepto de vector con el de coordenada, pues en la práctica se usan indistintamente, pero en teoría son conceptos diferentes. Cuando trabajemos con vectores en $\C^n$ usaremos la representación del vector como matriz columna, cuando trabajemos con coordenadas usaremos la representación del vector como matriz fila.

Cuando por comodidad en la notación necesitemos la representación del vector como matriz fila, usaremos la traspuesta del vector que denotaremos con la letra $^t$.

\begin{defi}
  Sea $\K$ un cuerpo.
  Un \textbf{espacio vectorial} sobre $\K$, o un $\K$-espacio vectorial, es un conjunto $\V$ no vacío junto con
  la operaciónes de suma interna sobre $\V$ y la operación multiplicación externa sobre $\V$ por elementos de $\K$, que
  verifica:
  \begin{enumerate}
    \item[\likeitem{E1}] $\V$ con la suma es un grupo.
    \item[\likeitem{E2}] Distributiva de la multiplicación en $\K$ con respecto a la suma en $\V$
          \[
            \forall k \in\K\ \forall u,v \in\V\Rightarrow k(u + v) = ku + kv\,.
          \]
    \item[\likeitem{E3}] Linealidad
          \[
            \forall k_{1},k_{2} \in\K\ \forall u \in\V\Rightarrow (k_{1} + k_{2})u = k_{1}u + k_{2}u\,.
          \]
    \item[\likeitem{E4}] Asociativa
          \[
            \forall k_{1},k_{2} \in\K\ \forall u \in\V\Rightarrow (k_{1}k_{2})u = k_{1}(k_{2}u)\,.
          \]
    \item[\likeitem{E5}] Neutro
          \[
            \forall u \in\V\Rightarrow 1u = u\,.
          \]
  \end{enumerate}

  A los elementos del espacio vectorial $\V$ se les llama  \textbf{vectores} y a los elementos del cuerpo $\K$ se les llama \textbf{escalares}.
\end{defi}

\begin{eje}
  $\C^n$ es un espacio vectorial sobre $\C$, con las operaciones usuales:
  \begin{align*}
    \mqty(x_1            \\ \vdots \\ x_n)
    + \mqty(y_1          \\ \vdots \\ y_n)
     & = \mqty(x_1 + y_1 \\ \vdots \\ x_n + y_n) \\
    k\mqty(x_1           \\ \vdots \\ x_n)
     & = \mqty(kx_1      \\ \vdots \\ kx_n)\,,
  \end{align*}
  para $k \in\C$ y $(x_1 \dots x_n)^t, (y_1 \dots y_n)^t\in\C^n$.
\end{eje}

\begin{eje}
  Las soluciones de un sistema homogéneo de ecuaciones lineales sobre un cuerpo $\K$.
\end{eje}

\begin{eje}
  Los polinomios en una variable con coeficientes en un cuerpo $\K$
  \[
    K\lbrack x\rbrack = \set{ a_{0} + a_{1}x + a_{2}x^{2} + \cdots + a_{n}x^{n} + \cdots\ \ |\ \ a_{i} \in\K,\ \forall i}
  \]
\end{eje}

\begin{eje}
  Las matrices $M_{m \times n}(\K)$ con la suma y produto por escalares habituales.
\end{eje}

\begin{eje}
  Si $\K$ es un cuerpo, también podemos verlo como un espacio vectorial sobre sí mismo.
\end{eje}

\begin{prop}
  Sea $V$ un $K$-espacio vectorial. Para todo $u\in V$ se cumple que
  \[
    0 \cdot u = 0\,.
  \]
\end{prop}
\begin{proof}
  Por la propiedad \likeitem{E3} tenemos que
  \[
    0 \cdot u = (0 + 0) \cdot u = 0 \cdot u + 0 \cdot u\,.
  \]
  Si sumamos el opuesto de $0 \cdot u$ a ambos miembros de la igualdad obtenemos
  \[
    0 = 0 \cdot u\,.
  \]
\end{proof}

\subsection{Subespacio vectorial complejo}

A partir de este momento, nos centraremos en espacios vectoriales sobre el cuerpo de los números complejos, es decir, en \(\C\)-espacios vectoriales. No obstante, la mayoría de los resultados que se presentarán son válidos para espacios vectoriales sobre cualquier cuerpo.

\begin{defi}
  Sea $\V$ un espacio vectorial.
  Diremos que $U \subseteq\V$ es un \textbf{subespacio vectorial} de $\V$ si:
  \begin{enumerate}
    \item $\forall u,v \in U$ entonces \(u + v \in U\).
    \item \(\forall u \in U\) y \(k \in \C\) entonces \(ku \in U\).
  \end{enumerate}
\end{defi}

Un subespacio vectorial es un subconjunto cerrado para las operaciones de suma y producto por un escalar.

\begin{prop}
  Sea $\V$ un espacio vectorial.
  Todo subespacio vectorial de $\V$ es también un espacio vectorial.
\end{prop}
\begin{proof}
  Sea $U$ un subespacio vectorial de $\V$. Como $\V$ es un espacio vectorial, entonces $(\V, +)$ es un grupo. Por tanto, la operación suma en $U$ es asociativa y conmutativa, existe el neutro y el opuesto para cada elemento de $U$.

  Además, las propiedades \likeitem{E2}, \likeitem{E3}, \likeitem{E4} y \likeitem{E5} se cumplen en $U$ porque se cumplen en $\V$ y $U \subseteq \V$.

  Por tanto, $U$ es un espacio vectorial.
\end{proof}

\begin{eje}
  Todo espacio vectorial tiene al menos un subespacio vectorial, llamado \textbf{subespacio trivial}, que es el conjunto que contiene únicamente el vector cero. Otros ejemplos no triviales son:
  \begin{itemize}
    \item La recta con ecuación \(\Ip(z) = 0\) es un subespacio vectorial de \(\mathbb{C}\).
    \item Las matrices triangulares inferiores forman un subespacio de \({M}_{n}(\C)\).
    \item Los polinomios de grado $n$ forman un subespacio de \(\C[X]\).
  \end{itemize}
\end{eje}

\begin{theo}[Caracterización de subespacios]
  Un subconjunto no vacío $W$ de un espacio vectorial $V$ es un subespacio si y solo si es cerrado bajo combinaciones lineales, es decir
  $$\alpha u + \beta v \in W \quad \forall u, v \in W, \, \forall\alpha, \beta \in \C\,.$$
\end{theo}

\subsection{Combinaciones lineales y sistemas generadores}

\begin{defi}[Combinación lineal]
  Sea $V$ un espacio vectorial. Una \textbf{combinación lineal} de los vectores $v_1, v_2, \ldots, v_k \in V$, es un vector de la forma
  $$\alpha_1 v_1 + \alpha_2 v_2 + \cdots + \alpha_k v_k,$$
  donde $\alpha_1, \alpha_2, \ldots, \alpha_k \in \C$.
\end{defi}

\begin{defi}[Subespacio generado]
  Sea $V$ un espacio vectorial. El subespacio generado por los vectores $v_1, v_2, \ldots, v_k\in V$ es
  $$\text{gen}\{v_1, v_2, \ldots, v_k\} = \left\{\sum_{i=1}^k \alpha_i v_i \mid \alpha_1, \ldots, \alpha_k \in \C\right\}\,.$$
\end{defi}

\begin{eje}
  Consideremos el espacio vectorial $\C^3$ y los vectores $v_1 = (1\, 0\, i)^t$ y $v_2 = (i\, 1\, 0)^t$, el subespacio vectorial generado por $S = \{v_1, v_2\}$ es
  $$\text{gen}(S) = \left\{\alpha \mqty(1\\ 0\\ i) + \beta \mqty(i\\ 1\\ 0) \mid \alpha, \beta \in \C\right\} = \left\{\mqty( \alpha + \beta i\\ \beta\\ \alpha i) \mid \alpha, \beta \in \C\right\}\,.$$
\end{eje}

\begin{defi}[Independencia lineal]
  Los vectores $v_1, v_2, \ldots, v_k$ en un espacio vectorial $V$ son \textbf{linealmente independientes} si la única solución de la ecuación
  $$\alpha_1 v_1 + \alpha_2 v_2 + \cdots + \alpha_k v_k = 0\,,$$
  es $\alpha_1 = \alpha_2 = \cdots = \alpha_k = 0$.

  En caso contrario, se dice que son \textbf{linealmente dependientes}.
\end{defi}

\begin{eje}
  Para determinar si los vectores $v_1 = (1\, i\, 0)^t$, $v_2 = (i\, 0\, 1)^t$, $v_3 = (1+i\, i\, 1)^t$ de $\C^3$ son linealmente independientes, planteamos la ecuación
  $$\alpha_1\mqty(1 \\ i \\0) + \alpha_2 \mqty(i\\ 0\\ 1) + \alpha_3 \mqty(1+i\\ i\\ 1) = \mqty(0\\ 0\\ 0)\,,$$
  que nos lleva al sistema de ecuaciones
  \begin{align*}
    \alpha_1 + i\alpha_2 + (1+i)\alpha_3 & = 0    \\
    i\alpha_1 + i\alpha_3                & = 0    \\
    \alpha_2 + \alpha_3                  & = 0\,.
  \end{align*}

  De la segunda ecuación, obtenemos que $\alpha_3 = -\alpha_1$, y de la tercera $\alpha_2 = -\alpha_3 = \alpha_1$. Sustituyendo en la primera
  $$\alpha_1 + i\alpha_1 + (1+i)(-\alpha_1) = \alpha_1 + i\alpha_1 - \alpha_1 - i\alpha_1 = 0\,.$$

  Esta ecuación se satisface para cualquier $\alpha_1$, por lo que los vectores son linealmente dependientes.

  Efectivamente podemos comprobar la dependencia lineal, pues
  \[
    v_3 = v_1 + v_2\,.
  \]
\end{eje}

\begin{prop}
  \begin{enumerate}
    \item Un conjunto que contiene el vector cero es linealmente dependiente.
    \item Si un conjunto, contiene un subconjunto de vectores linealmente dependiente, entonces el conjunto es linealmente dependiente.
    \item Es linealmente independiente todo subconjunto de un conjunto linealmente independiente.
    \item En $\C^n$, cualquier conjunto de más de $n$ vectores es linealmente dependiente.
    \item En $\C^n$, cualquier conjunto linealmente independiente tiene a lo sumo $n$ vectores.
  \end{enumerate}
\end{prop}

\subsection{Bases y dimensión}

\begin{defi}[Base]
  Un conjunto $\mathcal{B} = \{v_1, v_2, \ldots, v_n\}$ de vectores en un espacio vectorial $V$ es una \textbf{base} de $V$ si:
  \begin{enumerate}
    \item $\mathcal{B}$ es linealmente independiente.
    \item $\text{gen}(\mathcal{B}) = V$.
  \end{enumerate}
\end{defi}

\begin{eje}[Base canónica de $\C^n$]
  La base canónica (o estándar) de $\C^n$ es
  $$e_1 = \mqty(1\\0\\\vdots\\0), e_2 = \mqty(0\\1\\\vdots\\0), \ldots, e_n = \mqty(0\\0\\\vdots\\1)\,.$$

  Cualquier vector $v = (v_1, v_2, \ldots, v_n)^t \in \C^n$ se puede escribir como
  $$v = v_1 e_1 + v_2 e_2 + \cdots + v_n e_n\,.$$
\end{eje}

\begin{theo}[Existencia y unicidad de representación]
  Si $\mathcal{B} = \{v_1, v_2, \ldots, v_n\}$ es una base de un espacio vectorial $V$, entonces todo vector $v \in V$ se puede escribir de manera única como
  $$v = \alpha_1 v_1 + \alpha_2 v_2 + \cdots + \alpha_n v_n\,.$$
  Los escalares $\alpha_1, \alpha_2, \ldots, \alpha_n$ se llaman las \textbf{coordenadas} de $v$ respecto de la base $\mathcal{B}$ y lo denotaremos por
  \[
    v = (\alpha_1, \alpha_2, \ldots, \alpha_n)_\mathcal{B}\,.
  \]
\end{theo}

Cuando no se especifica la base, se está utilizando la base canónica.

El teorema de la existencia y unicidad de representación nos dice que una base nos permite expresar cualquier vector del espacio vectorial de una única manera como combinación lineal de los vectores de la base.

\begin{prop}
  Sea $V$ un espacio vectorial y $\mathcal{B}_1$ y $\mathcal{B}_2$ dos bases de $V$. Entonces, $\mathcal{B}_1$ y $\mathcal{B}_2$ tienen el mismo cardinal.
\end{prop}

Este resultado nos permite definir el siguiente concepto.

\begin{defi}[Dimensión]
  La dimensión de un espacio vectorial $V$ es el número de vectores en cualquiera de sus bases y se denota por $\dim(V)$.
\end{defi}

El concepto de dimensión es fundamental en álgebra lineal, ya que proporciona una medida del tamaño o grado de libertad del espacio vectorial. Un espacio vectorial puede ser de dimensión finita o infinita, dependiendo de si tiene una base con un número finito o infinito de vectores.

\begin{nota}
  Sólo vamos a considerar espacios vectoriales de dimensión finita, es decir, aquellos que tienen una base con un número finito de vectores. El tratamiento de espacios vectoriales de dimensión infinita requiere herramientas adicionales que no son necesarias para los objetivos de este curso.
\end{nota}

\begin{theo}[Propiedades fundamentales de la dimensión]
  Sea $V$ un espacio vectorial de dimensión $n$. Entonces:
  \begin{enumerate}
    \item Cualquier conjunto linealmente independiente de $n$ vectores es una base.
    \item Cualquier conjunto generador de $n$ vectores es una base.
    \item Si $W$ es un subespacio de $V$, entonces $\dim(W) \leq \dim(V)$.
  \end{enumerate}
\end{theo}

\begin{eje}
  Queremos encontrar una base para el subespacio $W$ de $\C^4$ definido por
  $$W = \left\{\mqty(x\\ y\\ z\\ w) \in \C^4 \mid x + y - z = 0, \, 2x - y + w = 0\right\}\,.$$
  De las ecuaciones que definen $W$, podemos expresar $z$ y $w$ en función de $x$ e $y$
  \begin{align*}
    x + y - z  & = 0 \Rightarrow z = x + y\,,  \\
    2x - y + w & = 0 \Rightarrow w = y - 2x\,.
  \end{align*}
  Por tanto, los vectores en $W$ tienen como coordenadas $(x, y, x+y, y-2x)$ que podemos expresar como combinación lineal de dos vectores
  $$\mqty(x\\ y\\ x+y\\ y-2x) = x\mqty(1\\ 0\\ 1\\ -2) + y\mqty(0\\ 1\\ 1\\ 1)\,.$$
  Esta expresión muestra nos da el conjunto generador de $W$, es decir,
  \[
    W = \text{gen}\left\{\mqty(1\\ 0\\ 1\\ -2), \mqty(0\\ 1\\ 1\\ 1)\right\}\,.
  \]

  Por último tenemos que verificar que los vectores encontrados son linealmente independientes, para ello tomemos una combinación lineal igualada al vector cero
  \[
    \alpha\mqty(1\\ 0\\ 1\\ -2) + \beta\mqty(0\\ 1\\ 1\\ 1) = \mqty(0\\ 0\\ 0\\ 0)\,.
  \]
  De la primera coordenada, obtenemos directamente que $\alpha = 0$, y de la segunda coordenada que $\beta = 0$, lo cual demuestra que los vectores son linealmente independientes.

  Así hemos encontrado un conjunto de vectores linealmente independientes y generador de $W$, es decir, una base.

  Por último podemos afirmar que $\dim(W) = 2$.
\end{eje}

Una de las razones por las cuales es importante el concepto de base, es porque podemos caracterizar cualquier elemento del espacio vectorial en función de los coeficientes usados al ser expresado como combinación lineal de los elementos de la base.

Elegir una base para un espacio vectorial de dimensión $n$ es equivalente a elegir un sistema de coordenadas para \(\C^n\).

\begin{eje}
  En \(\mathbb{P}_2[X]\) el vector \(p(x) = x^2+ix-8\) tiene coordenadas \((1, i, -8)\) en la base canónica, pero si consideramos la base \(\mathcal{B} = \{ x^2+ix-8, x + i, 1 \}\), entonces tenemos que \(x^2+ix-8 = (1,0, 0)_{\mathcal{B}}\).
\end{eje}

\begin{nota}
  Aunque se ha definido el concepto de base como un conjunto, en la práctica es habitual considerar las bases como listas ordenadas de vectores, pues el orden de los vectores en la base determina el orden de las coordenadas de un vector y este orden es importante.
\end{nota}

Gráficamente podemos visualizar un sistema de coordenadas como una malla o cuadrícula en la que las unidades de medida vienen determinadas por los elementos de la base.
Siguiendo con el ejemplo anterior, en la base canónica \( B=\left\{ e_{1},\ e_{2} \right\}\) la malla consiste en los ejes coordenados usuales (Figura~\ref{fig:bases-rejilla}, izquierda), mientras que en la base \(B^{\prime} = \left\{ b_{1},\ b_{2} \right\}\) la dirección vertical de la malla tiene un ángulo menor de 90 grados (Figura~\ref{fig:bases-rejilla}, derecha).

\begin{figure}[H]
  \centering
  \includegraphics[width=4.38189in,height=1.50394in]{imgs/bases-rejilla}
  \caption{Sistemas de coordenadas asociados a la base estándar  \( B=\left\{ e_{1},\ e_{2} \right\}\) (izquierda) y a la base  \(B^{\prime} = \left\{ b_{1},\ b_{2} \right\}\) (derecha). Fuente: Lay (2007, p. 248).}
  \label{fig:bases-rejilla}
\end{figure}

Observemos que el vector no cambia su posición (solamente la manera en la que es obtenido a partir de las dos bases).
También podemos observar que los tres vectores $x$, $b_1$ y $b_2$ pertenecen a la misma recta vertical en ambas
mallas.
Esto indica que el cambio de un sistema a otros o equivalentemente el cambio de una base a otra no afecta la estructura del espacio vectorial.
Formalizaremos este fenómeno más adelante al hablar de cambios de base o cambios de coordenadas.

\begin{eje}
  Consideremos el espacio vectorial de matrices de orden \(2 \times 3\) sobre $\C$.
  Las coordenadas de la matriz \(\begin{pmatrix}
    2    & - i & 4 \\
    2+3i & - 1 & 1
  \end{pmatrix}\) en la base canónica es \((2, - i,4,2+3i, - 1,1)\) y que como podemos observar es un espacio vectorial de dimensión $6$.
\end{eje}

\begin{defi}
  Sea $\V$ un espacio vectorial de dimensión $n$ y sean $\mathcal{B}$ y $\mathcal{B}^\prime$ dos bases de $\V$. Consideremos las coordenadas de los vectores $v_k$ de $\mathcal{B}$ en la base $\mathcal{B}^\prime$
  \[
    v_k = (a_{k1},\ldots,a_{kn})_{\mathcal{B}^\prime}\ \forall k=1,\dots,n\,.
  \]
  Llamamos \textbf{matriz cambio de coordenadas} de $\mathcal{B}$ a $\mathcal{B}^\prime$ a la matriz $M_{\mathcal{B}}^{\mathcal{B}^\prime}=(a_{ij})$.
\end{defi}

Dado $v$ un vector de $\V$ con coordenadas $(x_1,\dots,x_n)_{\mathcal{B}}$ y coordenadas $(y_1,\dots,y_n)_{\mathcal{B}^\prime}$, tenemos
\begin{align*}
  v & =\sum_{i=1}^n x_i v_i=\sum_{i=1}^n x_i \left( \sum_{j=1}^n a_{ij}v_j^\prime\right) =\sum_{j=1}^n \left( \sum_{i=1}^n x_i a_{ij}\right) v_j^\prime \\
  v & =\sum_{j=1}^n y_j v_j^\prime\,.
\end{align*}
Por la unicidad de la representación obtenemos
\[
  y_j                                  = \sum_{i=1}^n x_i a_{ij} = (x_1,\dots,x_n)_{\mathcal{B}}(M_{\mathcal{B}}^{\mathcal{B}^\prime})^j\,,
\]
y por tanto
\[
  (y_1,\dots,y_n)_{\mathcal{B}^\prime} = (x_1,\dots,x_n)_{\mathcal{B}}M_{\mathcal{B}}^{\mathcal{B}^\prime}\,.
\]

La ecuación matricial del cambio de coordenadas de $\mathcal{B}$ a $\mathcal{B}^\prime$ permite calcular las coordenadas de un vector en la base $\mathcal{B}^\prime$ conociendo las coordenadas con respecto a la base $\mathcal{B}$.

\begin{eje}
  Consideremos en \(\mathbb{C}^{2}\) los vectores
  \[
    u_1 = \mqty(2\\4), \quad u_2 = \mqty(-1\\2), \quad v_1 = \mqty(1\\0), \quad v_2 = \mqty(i\\2)\,,
  \]
  y las bases $\mathcal{B}=\set{u_1, u_2}$ y $\mathcal{B}^{\prime}=\set{v_1, v_2}$.

  Para calcular la matriz de cambio de coordenadas de $\mathcal{B}$ a $\mathcal{B}^{\prime}$ debemos primero conocer cuál es la expresión de los vectores de $\mathcal{B}$ en función de los vectores de $\mathcal{B}^{\prime}$.
  Para ello tenemos que resolver el sistema de ecuaciones
  \begin{align*}
    \mqty(2  \\4) & = a\mqty(1\\0)+b\mqty(i\\2)  \\
    \mqty(-1 \\2) & = c\mqty(1\\0)+d\mqty(i\\2).
  \end{align*}
  La solución es \(a = 2-2i,\, b = 2\) y \(c = -1-i,\ d = 1\), por lo que
  \begin{align*}
    u_1 & = (2-2i, 2)_{\mathcal{B}^\prime}    \\
    u_2 & = (-1-i, 1)_{\mathcal{B}^\prime}\,.
  \end{align*}

  La matriz de cambio de coordenadas de $\mathcal{B}$ a $\mathcal{B}^\prime$ es
  \[
    M_{\mathcal{B}}^{\mathcal{B}^\prime} = \mqty(2-2i & 2 \\ -1-i & 1).
  \]
  Hagamos la comprobación, en la base $\mathcal{B}$ tenemos que \(u_2 = (0,1)_{\mathcal{B}}\).
  Multiplicando las coordenadas por la matriz $M_{\mathcal{B}}^{\mathcal{B}^\prime} $ tenemos que
  \[
    (0,1)_{\mathcal{B}} M_{\mathcal{B}}^{\mathcal{B}^\prime} = (-1-i, 1)_{\mathcal{B}^\prime}\,,
  \]
  y aplicando estas coordenadas en la base $\mathcal{B}^\prime$ tenemos que
  \[
    (-1-i, 1)_{\mathcal{B}^\prime} = (-1-i)v_1 + 1\cdot v_2 = (-1-i)\mqty(1\\0) + 1\cdot \mqty(i\\2) = \mqty(-1\\2)=u_2\,.
  \]
  Resumiendo
  \[
    u_2 = (0,1)_{\mathcal{B}} = (-1-i, 1)_{\mathcal{B}^\prime}\,.
  \]
\end{eje}

El cambio de coordenadas en el sentido contrario, es decir, calcular las coordenadas de un vector en la base $\mathcal{B}$ conociendo sus coordenadas en la base $\mathcal{B}^\prime$ viene dado por la matriz inversa.

\begin{prop}
  Sea $\V$ un espacio vectorial de dimensión $n$ y sean $\mathcal{B}$ y $\mathcal{B}^\prime$ dos bases de $\V$. La matriz cambio de coordenadas de $\mathcal{B}^\prime$ a $\mathcal{B}$ es la inversa de la matriz de cambio de coordenadas de $\mathcal{B}$ a $\mathcal{B}^\prime$
  \[
    M_{\mathcal{B}^\prime}^{\mathcal{B}} = \left(M_{\mathcal{B}}^{\mathcal{B}^\prime}\right)^{-1}\,.
  \]
\end{prop}

\begin{eje}
  Siguiendo con el ejemplo anterior, podemos ahora calcular la matriz de cambio de coordenadas de $\mathcal{B}^\prime$ a $\mathcal{B}$ a partir de la matriz de cambio de coordenadas de $\mathcal{B}$ a $\mathcal{B}^\prime$ calculando la inversa
  \[
    M_{\mathcal{B }^\prime}^{\mathcal{B}} = \left(M_{\mathcal{B}}^{\mathcal{B}^\prime}\right)^{-1} = \frac{1}{4}\mqty(1 & -2 \\ 1+i & 2-2i).
  \]

  Hagamos la comprobación, en la base $\mathcal{B}^\prime$ tenemos que \(v_1 = (1,0)_{\mathcal{B}^\prime}\).
  Multiplicando a este vector la matriz $M_{\mathcal{B}^\prime}^{\mathcal{B}} $ tenemos que
  \[
    (1,0)_{\mathcal{B}^\prime}\frac{1}{4}\mqty(1 & -2 \\ 1+i & 2-2i) = (\frac{1}{4},-\frac{1}{2})_{\mathcal{B}}\,,
  \]
  y aplicando estas coordenadas en la base $\mathcal{B}$ tenemos que
  \[
    (\frac{1}{4},-\frac{1}{2})_{\mathcal{B}} = \frac{1}{4}u_1 - \frac{1}{2}u_2 = \frac{1}{4}\mqty(2\\4) - \frac{1}{2}\mqty(-1\\2) = \mqty(\frac{1}{2}\\1) - \mqty(-\frac{1}{2}\\1) = \mqty(1\\0)=v_1\,.
  \]
  Resumiendo
  \[
    v_1 = (1,0)_{\mathcal{B}^\prime} = (\frac{1}{4},-\frac{1}{2})_{\mathcal{B}}\,.
  \]
\end{eje}

\begin{prop}
  Sea $\V$ un espacio vectorial de dimensión $n$ y sean $\mathcal{B}_1$, $\mathcal{B}_2$ y $\mathcal{B}_3$ tres bases de $\V$. La matriz cambio de coordenadas de $\mathcal{B}_1$ a $\mathcal{B}_3$ se calcula como el producto de la matriz cambio de coordenadas de $\mathcal{B}_1$ a $\mathcal{B}_2$ y la matriz cambio de coordenadas de $\mathcal{B}_2$ a $\mathcal{B}_3$.
  \[
    M_{\mathcal{B}_1}^{\mathcal{B}_3} = M_{\mathcal{B}_1}^{\mathcal{B}_2}M_{\mathcal{B}_2}^{\mathcal{B}_3}\,.
  \]
\end{prop}

\begin{eje}
  Siguiendo con el ejemplo anterior, calculemos la matriz de cambio de coordenadas de $\mathcal{B}^\prime$ a $\mathcal{B}$ usando la base canónica $\mathcal{C}$, como base intermedia.

  Este método es más sencillo ya que tenemos expresados los vectos de ambas bases como coordenadas de la base canónica, así que la matriz cambio de coordenadas entre $\mathcal{B}$ y la canónica es la matriz cuyas filas son las coordenadas de los vectores de $\mathcal{B}$.

  La matriz de cambio de coordenadas de $\mathcal{B}$ a $\mathcal{C}$ es
  \[
    M_{\mathcal{B}}^{\mathcal{C}} = \mqty(2 & 4 \\ -1 & 2)\,,
  \]

  mientras que la matriz de cambio de coordenadas de $\mathcal{B}^\prime$ a $\mathcal{C}$ es
  \[
    M_{\mathcal{B}^\prime}^{\mathcal{C}} = \mqty(1 & 0 \\ i & 2).
  \]
  Por lo tanto, la matriz de cambio de coordenadas de $\mathcal{B}$ a $\mathcal{B}^\prime$ es
  \begin{align*}
    M_{\mathcal{B}}^{\mathcal{B}^\prime} & = M_{\mathcal{B}}^{\mathcal{C}}M_{\mathcal{C}}^{\mathcal{B}^\prime} = \mqty(2 & 4 \\ -1 & 2) \mqty(1 & 0 \\ i & 2)^{-1} \\
                                         & = \mqty(2                                                                     & 4 \\ -1 & 2) \frac{1}{2}\mqty(2                                                          & 0 \\ -i & 1)                                                  \\
                                         & = \frac{1}{2}\mqty(4-4i                                                       & 4 \\ -2-2i & 2)\\
                                         & = \mqty(2-2i                                                                  & 2 \\ -1-i & 1)\,.
  \end{align*}
\end{eje}

Si consideramos la matriz traspuesta de $M_\mathcal{B}^\mathcal{C}$ del ejemplo anterior y multiplicamos por los vectores de la base canónica, obtenemos
\begin{align*}
  \mqty(2 & -1 \\ 4 & 2)\mqty(1\\0) &= \mqty(2\\4)\\
  \mqty(2 & -1 \\ 4 & 2)\mqty(0\\1) &= \mqty(-1\\2)\,.
\end{align*}
Generalizando este resultado tenemos una expresión para realizar un cambio de base.

\begin{prop}
  Sea $V$ un espacio vectorial, $\mathcal{C}=\{e_1,\dots,e_n\}$ la base canónica y $\mathcal{B}=\{u_1,\dots,u_n\}$ una base de $V$. Se cumple que
  \[
    \left(M_{\mathcal{B}}^{\mathcal{C}}\right)^t e_i = u_i\,.
  \]
\end{prop}

Por último si consideramos dos bases distintas, podemos obtener una matriz que lleve vectores de una base en la otra, pues
\[
  \begin{rcases}
    \left(M_{\mathcal{B}}^{\mathcal{C}}\right)^t e_i = u_i \Rightarrow  e_i = \left(\left(M_{\mathcal{B}}^{\mathcal{C}}\right)^t\right)^{-1} u_i \\
    \left(M_{\mathcal{B^\prime}}^{\mathcal{C}}\right)^t e_i = v_i
  \end{rcases}\Rightarrow v_i = \left(M_{\mathcal{B^\prime}}^{\mathcal{C}}\right)^t \left(M_{\mathcal{C}}^{\mathcal{B}}\right)^t u_i = \left(M_{\mathcal{C}}^{\mathcal{B}} M_{\mathcal{B^\prime}}^{\mathcal{C}}\right)^t u_i\,,
\]
este resultado justifica la siguiente definición

\begin{defi}
  Sea $V$ un espacio vectorial, $\mathcal{B}$ y $\mathcal{B^\prime}$ dos bases de $V$. Llamamos \textbf{matriz cambio de base} de $\mathcal{B}$ a $\mathcal{B}^\prime$a
  \[
    M_{\mathcal{B}\mathcal{B^\prime}} = \left(M_{\mathcal{C}}^{\mathcal{B}} M_{\mathcal{B^\prime}}^{\mathcal{C}}\right)^t\,.
  \]
\end{defi}
\subsection{Intersección y suma de subespacios}

\begin{prop}
  Sea $\V$ un espacio vectorial y $U,W$ dos subespacios vectoriales $\V$. La intersección $U \cap W$ es un subespacio vectorial de $\V$.
\end{prop}

En general, la unión de dos subespacios vectoriales no es un subespacio vectorial, ya que no está cerrada bajo la suma. Por este motivo definimos la suma de dos subespacios vectoriales como el subespacio generado por su unión.

\begin{defi}[Suma de subespacios]
  Sea $\V$ un espacio vectorial y $U,W$ dos subespacios vectoriales de $\V$. Definimos la \textbf{suma} de $U$ y $W$ como
  \[
    U + W = \left\langle U \cup W \right\rangle\,.
  \]
\end{defi}

\begin{prop}
  Sean $\V$ y $W$ dos espacios vectoriales, se tiene
  \[
    \dim(\V + W) = \dim(\V) + \dim(W) - \dim(\V\cap W)
  \]
\end{prop}

\begin{defi}
  Sea $\V$ un espacio vectorial y $U,W$ dos subespacios vectoriales $\V$.
  Decimos que $U+W$ es \textbf{suma directa} si \(U \cap W = \{0\}\). Denotamos la suma directa como \(U \oplus W\).
\end{defi}

\begin{prop}
  Sea $V$ un espacio vectorial y $U,W$ dos subespacios vectoriales $\V$. Si \(V = U\oplus W\) entonces todo vector \(v \in V\) se puede escribir como \(v = u + w\) para \(u \in U,\ w \in W\) de manera única.
\end{prop}
\begin{defi}
  Sea $V$ un espacio vectorial y $U,W$ dos subespacios vectoriales $\V$ tal que \(V = U\oplus W\). Sea \(v \in V\) como suma de \(v = u + w\) para \(u \in U,\ w \in W\).  Al vector \(u\) se le llama la \textbf{proyección} de $v$ en \(U\) y al vector \(w\) la \textbf{proyección} de $v$ en \(W\).
\end{defi}

\begin{eje}
  Usando coordenadas y considerando en \(\mathbb{C}^{3}\) los subespacios
  \[
    U = \set{(x,y,z) \in \mathbb{C}^{3} \mid x + y + z = 0}
  \]
  y
  \[
    W = \set{(x,y,z) \in \mathbb{C}^{3} \mid x = y = z}.
  \]
  Podemos ver que \(U \cap W = \{0\}\) por lo que la suma es directa.
  Además, como \(\dim(U) = 2\) y \(\dim(W) = 1\), tenemos que \(\dim(U) + \dim(W) = 3 = \dim(\mathbb{C}^{3})\), por lo que \(\mathbb{C}^{3} = U \oplus W\).

  Por último, consideremos el vector \(v = (2,3,-2)\). Podemos escribirlo como suma de un vector de \(U\) y otro de \(W\):
  \[
    v = (2,3,-2) = (1,2,-3) + (1,1,1)
  \]
  donde \((1,2,-3) \in U\) y \((1,1,1) \in W\).
  Así, la proyección de \(v\) en \(U\) es \((1,2,-3)\) y la proyección de \(v\) en \(W\) es \((1,1,1)\).
\end{eje}

\begin{prop}
  Sea $V$ un espacio vectorial y $S=\{v_1, v_2, \ldots, v_k\}$ un conjunto de vectores en $V$ linealmente independientes. Entonces, el subespacio generado por $S$ es suma directa de los subespacios generados por cada vector individualmente, es decir
  \[
    \text{gen}(S) = \text{gen}(v_1) \oplus \text{gen}(v_2) \oplus \cdots \oplus \text{gen}(v_k)\,.
  \]
\end{prop}

Y por último, para terminar el estudio de como descomponer un espacio vectorial en subespacios, nos falta un resultado de extensión

\begin{prop}
  Sea $V$ un espacio vectorial y $U$ un subespacio vectorial de $V$. Existe un único subespacio vectorial $W$ de $V$ con la propiedad
  \[
    V = U \oplus W\,.
  \]
\end{prop}

En los siguientes temas, daremos más detalles sobre como construir estos subespacios y que propiedades deben cumplir, así como obtener aquellos subespacios que nos permita obtener una representación sencilla de un espacio cuántico en un espacio vectorial.